---
title: Les méthodes perturbatrices
subtitle: |
  **[Pour données tabulées ou individuelles]{.orange}**
order: 3
href: theorie/supports/methodes-perturbatrices.html
image: ../../images/theorie.png
# date: 
slide-number: true
header: |
  [Retour à l'accueil](https://inseefrlab.github.io/formation_protection_donnees)
footer: |
  Les méthodes de protection statistique des données confidentielles
# uncomment for French presentations:
lang: fr-FR
# for blind readers:
slide-tone: false
# for @olevitt:
# chalkboard: # press the B key to toggle chalkboard
#   theme: whiteboard
# uncomment to use the multiplex mode:
#multiplex: true
format:
  onyxia-revealjs:
    number-sections: true
    number-depth: 1
    toc: true
    toc-depth: 1
    toc-title: Sommaire
tbl-cap-location: bottom
controls: true
include-in-header: 
  text: |
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">
css: custom.css
# from: markdown+emoji
# listing:
#   id: sample-listings
#   contents: teaching
#   sort: "date desc"
#   type: table
bibliography: ../../references-SDC.bib
# csl: ../style.csl  # Décommentez besoin d'un style de biblio spécifique
---


# Introduction {.unnumbered}


## Objectifs

::: {style="font-size: 80%;"}

- Quelles sont les méthodes perturbatrices qui permettent de limiter les risques de divulgation ?  
- Quelles méthodes s'appliquent aux données tabulées, lesquelles aux données individuelles ?  
- De quel type de risque les méthodes nous protègent-elles?  
- Quels sont les conséquences sur la perte d'information ?  

:::

## Les méthodes principales à disposition

::: {#tbl-class-meth}

<style type="text/css">
.tg  {border-collapse:collapse;border-color:#C44D58;border-spacing:0;}
.tg td{background-color:#F9CDAD;border-color:#C44D58;border-style:solid;border-width:2px;color:#002b36;
  font-family:Arial, sans-serif;font-size:24px;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg th{background-color:#FE4365;border-color:#C44D58;border-style:solid;border-width:1px;color:#fdf6e3;
  font-family:Arial, sans-serif;font-size:28px;font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-ouj0{border-color:#fdf6e3;text-align:center;vertical-align:top}
.tg .tg-ukzp{border-color:#fdf6e3;font-weight:bold;text-align:center;vertical-align:top}
.tg .tg-jusz{background-color:#fe4365;border-color:#fdf6e3;color:#fdf6e3;font-weight:bold;text-align:center;vertical-align:top}
</style>
<table class="tg"><thead>
  <tr>
    <th class="tg-ukzp"></th>
    <th class="tg-ukzp" colspan="2">Méthodes</th>
  </tr></thead>
<tbody>
  <tr>
    <td class="tg-jusz">Traitements</td>
    <td class="tg-jusz">Non-Perturbatrices</td>
    <td class="tg-jusz">Perturbatrices</td>
  </tr>
  <tr>
    <td class="tg-jusz" rowspan="3"><br>Avant tabulation <br>(sur micro-données)<br></td>
    <td class="tg-ouj0">Ré-échantillonnage</td>
    <td class="tg-ouj0">Injection de bruit</td>
  </tr>
  <tr>
    <td class="tg-ouj0">Recodage des variables</td>
    <td class="tg-ouj0">Micro-agrégation</td>
  </tr>
  <tr>
    <td class="tg-ouj0">Suppression locale</td>
    <td class="tg-ouj0">Swapping (rang ou ciblé)</td>
  </tr>
  <tr>
    <td class="tg-jusz" rowspan="3"><br>Après tabulation <br>(sur données agrégées)<br></td>
    <td class="tg-ouj0">Recodage des variables</td>
    <td class="tg-ouj0">Arrondis</td>
  </tr>
  <tr>
    <td class="tg-ouj0">Suppression de cases</td>
    <td class="tg-ouj0">Clés aléatoires</td>
  </tr>
  <tr>
    <td class="tg-ouj0"></td>
    <td class="tg-ouj0">Algo de confidentialité différentielle</td>
  </tr>
</tbody></table>

: Les méthodes pour gérer la protection des données

:::

Il existe aussi une autre technique consistant à produire des données synthétiques.


## Perturbatif vs suppressif

Dans quels cas préférer les méthodes perturbatrices aux méthodes suppressives?

- Prise en charge de diffusions complexes à traiter avec des méthodes suppressives: 
  - nombreux tableaux (diffusion industrielle),
  - diffusion en plusieurs moments
  - différenciation géographique ou de nomenclature
- Contrôler la perte d'utilité plus finement:
  - un arbitrage possible en général en jouant sur les paramètres du bruit
  - pas de suppression => une information disponible et manipulable
- Un cadre institutionnel qui autorise un tel usage

## Perturbatif vs suppressif

Certaines limites des méthodes perturbatrices:

- Dans certains cas, perte de caractéristiques basiques des données (additivité dans les tableaux)
- Une perception du traitement du secret moins immédiate qu'avec le blanchiment
- Une pédagogie nécessaire vis-à-vis du public pour l'utilisation des données
- Des règles historiques de secret à revisiter car adaptées pour des méthodes suppressives


# Les méthodes post-tabulation

## Les méthodes post-tabulation

- Méthodes qui sont appliquées sur les données agrégées
- Certaines méthodes (en particulier les arrondis) sont plus adaptées aux comptages qu'aux volumes
- Perturbation de tout ou partie des tableaux selon la méthode

## Quelques enjeux ?

En perturbant les données dans des tableaux:

- Faut-il tout perturber ou seulement une partie ?
- Comment assurer la cohérence entre les tableaux ?
- Faut-il préserver l'additivité au sein des tabeaux ?

En répondant à ces questions, on s'orientera vers une méthode plutôt qu'une autre.


# Méthodes d'arrondi et apparentées

## Méthodes d'arrondi et apparentées

- Arrondis déterministes 
- Arrondis aléatoires
- Small Count Rounding
- Controlled Rounding

Des méthodes principalement adaptées aux tableaux de comptages.  

Pour plus d'informations: [https://sdctools.github.io/HandbookSDC/05-frequency-tables.html#sec-Rounding_freq]() [@hundepool_handbook_2024]



## Un exemple

Supposons le tableau de comptage suivant (en gras les informations jugées sensibles)

::: {#tbl-compt-orig .table .table-striped .table-hover .table-bordered}


| Caractéristique | Nord  | Ouest |  Sud  | Est | Total |
| :-------------: | :---: | :---: | :---: | :-: | :---: |
|    Polluante    |   6   |  14   | **1** |  7  |  28   |
|  Non-Polluante  | **3** | **2** | **1** | 13  |  19   |
|      Total      |   9   |  16   | **2** | 20  |  47   |
: Nombre d'entreprises en fonction de leur implantation et du caractère polluant de leurs activités

:::

## Arrondis déterministes ou aléatoires

::: {.callout-note}
### Arrondir
Arrondir un comptage $x$, c'est ramener sa valeur à un multiple de la base d'arrondi $b$ choisie:

- Soit au multiple le plus proche (arrondi déterministe)
  - => Un arrondi déterministe renvoie toujours la même valeur
- Soit, aléatoirement, à l'un des deux multiples les plus proches (arrondi aléatoire).
  - L'arrondi est sans biais en choisissant les probabilités adéquates.
  - Cette technique offre une meilleure protection
:::

::: {.callout-tip}
### Exemple
$b=10$ et $x=23$:

- Arrondi déterministe: $x^\prime = 20$.
- Arrondi aléatoire: 
  - $x^\prime = 20$ avec probabilité de $0.7$ ou
  - $x^\prime = 30$ probabilité de $0.3$.
:::


## Un exemple

::: {#tbl-compt-arr .table .table-striped .table-hover .table-bordered}
| Caractéristique |  Nord  | Ouest  |  Sud  |  Est   | Total  |
| :-------------: | :----: | :----: | :---: | :----: | :----: |
|    Polluante    | **5**  | **15** | **0** | **5**  | **30** |
|  Non-Polluante  | **5**  | **0**  | **0** | **15** | **20** |
|      Total      | **10** | **15** | **0** |   20   | **45** |

: Application d'un arrondi déterministe de base $b=5$ (Moyenne des écarts absolus: $1.4$.)

:::


##  Arrondis des petits comptages


::: {.callout-note}
### Small Count Rounding
Algorithme appliqué à des tableaux de données assurant:

- l'arrondi des petits comptages (cad les plus sensibles) dans une base $b$
- des comptages supplémentaires sont déviés pour:
  - conserver l'additivité dans les tableaux
  - et minimiser la perturbation globale

Technique implémentée dans le package `R` `SmallCountRounding`
:::



## Un exemple

::: {#tbl-compt-smcr .table .table-striped .table-hover .table-bordered}


| Caractéristique |  Nord  | Ouest  |  Sud  | Est | Total  |
| :-------------: | :----: | :----: | :---: | :-: | :----: |
|    Polluante    |   6    |   14   | **0** |  7  |   28   |
|  Non-Polluante  | **5**  | **0**  | **0** | 13  | **18** |
|      Total      | **11** | **14** | **0** | 20  | **45** |

: Application d'un algorithme de type Small Count Rounding (Moyenne des écarts absolus: $1.07$.)

:::

##  Arrondi contrôlé 

::: {.callout-note}
### Controlled Rounding
Algorithme appliqué à des tableaux de données assurant:

- l'arrondi de tous les comptages selon une base $b$
- tout en assurant:
  - la conservation de l'additivité dans les tableaux
  - la minimisation de la somme des différences absolues entre valeurs originales et arrondies

Technique implémentée dans le logiciel `Tau-ARGUS` 
:::

<!---
## Controlled Tabular adjustment (CTA)

Les valeurs des cellules sensibles sont perturbées pour respecter un **intervalle de protection**. Les autres cellules sont ajustées pour restaurer l'additivité dans les tableaux.
--->


## Un exemple

::: {#tbl-compt-arr-ctr .table .table-striped .table-hover .table-bordered}


| Caractéristique |  Nord  | Ouest  |  Sud  |  Est   | Total  |
| :-------------: | :----: | :----: | :---: | :----: | :----: |
|    Polluante    | **5**  | **15** | **0** | **5**  | **25** |
|  Non-Polluante  | **5**  | **2**  | **0** | **15** | **20** |
|      Total      | **10** | **15** | **0** | **20** | **45** |

: Application d'un arrondi contrôlé avec une base $b=5$ (Moyenne des écarts absolus: $1.5$.)

:::

<!---
## Controlled Tabular Adjustment 
::: frame

avec un intervalle de protection = $[0;5]$

         Région                                    
  ----- -------- -------- -------- ------- ------- ----
   3-7    Nord    Ouest     Est      Sud    Total  
          Oui     **5**    **16**   **0**     7     28
   2-7    Non     **6**    **0**    **0**    13     19
   2-7   Total    **11**     16     **0**    20     47

Moyenne des écarts absolus: $0.933$.
:::

## Avantages / inconvénients

  **Avantages**                                                      **Inconvénients**
  ------------------------------------------------------------------ -------------------------------------------------------------------------------------------------------
  Conservation de l'additivité                                       CR et CTA: Recherche de la solution optimale sur grands tableaux très couteuse en temps (optim. lin.)
  SCR: Algorithme très efficace sur R                                CR: Une perte d'information parfois excessive
  Perception de la protection (en particulier des petites valeurs)   Difficile à utiliser dans le cadre d'une diffusion complexe

--->

# La méthode des clés aléatoires (CKM)

::: {.callout-note}
### La méthode des clés aléatoires

Méthode qui consiste à dévier tous les comptages indépendamment les uns des autres:

- chaque comptage est dévié d'une valeur comprise entre $-D$ et $+D$, $D$ étant un paramètre de la méthode;
- une case est toujours perturbée de la même manière grâce à l'utilisation de **clés individuelles**
- un comptage nul n'est pas perturbé;
- la quantité de bruit injecté dans les tableaux est de variance $V$, un autre paramètre de la méthode.

Sources: @thompson_methodology_2013, @chipperfield_australian_2016, @giesing_concepts_2019
:::

## La distribution de probabilités

Propriétés :

-   Une déviation maximale D et une variance V sont fixés en amont

-   Le bruit injecté est sans biais

-   La loi de probabilité de la déviation injectée est définie à partir d'une matrice de transition


## Un exemple

::: {#tbl-compt-ckm .table .table-striped .table-hover .table-bordered}


| Caractéristique |  Nord  | Ouest  |  Sud  |  Est   | Total  |
| :-------------: | :----: | :----: | :---: | :----: | :----: |
|    Polluante    | **4**  | **15** | **0** | **8**  | **28** |
|  Non-Polluante  | **1**  | **3**  | **2** | **15** | **20** |
|      Total      | **10** | **16** | **4** | **21** | **46** |

: Application de la CKM avec $D = 5$ et $V = 3$ (Moyenne des écarts absolus: $1.1$)

:::


## Les usages

La méthode est utilisée par plusieurs INS:

-   Depuis 2006, ABS met à disposition un outil de requêtage en ligne pour obtenir des données de son recensement quinquennal. Les données sont protégées avec la CKM. (<https://tablebuilder.abs.gov.au>)

-   La CKM est une des méthodes préconisées par Eurostat pour protéger les données du Census européen 2021.

-   Dans ce cadre, Destatis utilise la CKM pour diffuser des données sur des grilles de 500m.

-   2024/2025: l'Insee diffuse les données sur les Quartiers de la Politique de la Ville (QPV).


## Etape 1: Création d'une clé individuelle aléatoire

::: {style="text-align:center;"}
![Arbitrer](img/ckm-ind-cles.png){#fig-mat-trans width=90% fig-alt="Ajout des clés individuelles aux micro-données" fig-align="center"}
:::

<!---
Supposons que la base $\mathcal{B}$ soit composé des 6 individus suivant et qu'à chacun on associe une clé :

::: {#tbl-ckm-ind .table .table-striped .table-hover .table-bordered}

  **id**   **Ville**   **Ecole**    **KEY**
-------- ----------- ----------- -----------
    1       Rennes       Ensai     0.9177275
    2        Paris       Mines     0.1850062
    3       Rennes       Ensai     0.6266963
    4        Lyon      Centrale    0.1117820
    5      Marseille   Centrale    0.6496634
    6        Lille     Centrale    0.2813433

: Ajout d'une clé aléatoire dans le jeu de données individuelles
:::
--->

## Etape 2: Construction du tableau

::: {style="text-align:center;"}
![Construction du tableau et des clés de chaque case](img/ckm-table-depart.png){#fig-mat-trans width=90% fig-alt="Construction du tableau et des clés de chaque case" fig-align="center"}
:::

<!-- 
Nous souhaitons diffuser le nombre d'individus selon leur école.

On a :

::: center
   **Ecole**   **i**   **individus**   **Skey**     **CK**
  ----------- ------- --------------- ----------- -----------
     Ensai       2         {1,3}       1.544424    0.544425
     Mines       1          {2}        0.1805062   0.1805062
   Centrale      3        {4,5,6}      1.0422789    0.42789
     Total       6     {1,2,3,4,5,6}   2.772219    0.772219
::: -->

## Etape 3: Les probabilités de transition

::: {style="text-align:center;"}
![Matrice de transition pour D=2 et V=1](img/ckm-mat-trans.png){#fig-mat-trans width=90% fig-alt="Matrice de transition pour D=2 et V=1" fig-align="center"}
:::


<!---
```{r}
#| echo: false
#| fig-align: center
#| fig-cap: Probabilités de transition pour $D = 3$ et $V = 1.5$
#| label: fig-cnt-table
library(ptable)
plot(ptable::create_cnt_ptable(D=3, V=1.5), type="p")
```
--->


## Etape 4 : Déterminer la perturbation à injecter

::: {style="text-align:center;"}
![La perturbation à injecter" fig-align="center](img/ckm-table-pert.png){#fig-tab-pert width=90% fig-alt="La perturbation à injecter" fig-align="center"}
:::
<!-- 
   i   j       p        v     p_int_lb     p_int_ub
  --- --- ------------ ---- ------------ ------------
   0   0   1.00000000   0    0.00000000   1.00000000
   1   0   0.37967089   -1   0.00000000   0.37967089
   1   1   0.37967089   0    0.37967089   0.75934178
   1   2   0.13660124   1    0.75934178   0.89594302
   1   3   0.06910130   2    0.89594302   0.96504432
   1   4   0.03495568   3    0.96504432   1.00000000
   2   0   0.11466600   -2   0.00000000   0.11466600
   2   1   0.24491770   -1   0.11466600   0.35958370
   2   2   0.30449462   0    0.35958370   0.66407832
   2   3   0.22034995   1    0.66407832   0.88442827
   2   4   0.09281544   2    0.88442827   0.97724371
   2   5   0.02275629   3    0.97724371   1.00000000
   3   0   0.01792237   -3   0.00000000   0.01792237
   3   1   0.08898737   -2   0.01792237   0.10690974
   3   2   0.23274919   -1   0.10690974   0.33965893
   3   3   0.32068214   0    0.33965893   0.66034107
   3   4   0.23274919   1    0.66034107   0.89309026
   3   5   0.08898737   2    0.89309026   0.98207763
   3   6   0.01792237   3    0.98207763   1.00000000
::: -->

## Etape 5 : Construire le tableau final

::: {style="text-align:center;"}
![Table après perturbation](img/ckm-table-finale.png){#fig-tab-finale width=90% fig-alt="Table après perturbation" fig-align="center"}
:::

<!-- 
::: center
   **Ecole**   **Valeur originale i**   **Valeur pertubée j**     
  ----------- ------------------------ ----------------------- -- --
     Ensai               2                        2               
     Mines               1                        0               
   Centrale              3                        3               
     Total               6                        7               
:::
::: -->

## Avantages / inconvénients

::: {#tbl-ckm-avtg-incv style="font-size: 70%;" .table .table-striped .table-hover}
|                       Avantages                        |                                Inconvénients                                 |
| :----------------------------------------------------: | :--------------------------------------------------------------------------: |
|                Facile d'implémentation                 |                            Perte de l'additivité                             |
|                 Cohérence des tableaux                 |                 Perception de gestion du secret moins facile                 |
|         Réduit les risques de différenciation          | Cumulation des bruits pour les statistiques de second ordre (ratios par ex.) |
|              Compatible avec le requêtage              |                                                                              |
|        Compatible avec une diffusion sur mesure        |                                                                              |
| A protection égale, meilleure utilité que les arrondis |                                                                              |

: Avantages et onconvénients de la méthode des clés aléatoires
:::


# La microagrégation

-   Méthode perturbatrice, plus adaptée aux variables continues, mais peut-être adaptée aux variables catégorielles ordonnées

-   Idée principale :

    -   **Créer des petits groupes homogènes** en prenant en compte les valeurs des variables sélectionnées

    -   **Remplacer les valeurs** de tous les individus appartenant au groupe **par une unique valeur** (peut être la valeur moyenne de valeurs observées dans le groupe)

## Un exemple

::: {#tbl-ckm-avtg-incv style="font-size: 70%;" .table .table-striped .table-hover .table-bordered}

| Région | Âge | Heures travaillées par semaine | Revenu mensuel |
| :----: | :-: | :----------------------------: | :------------: |
|   92   | 36  |               17               |      1000      |
|   75   | 41  |               35               |      2000      |
|   75   | 52  |               0                |      1100      |
|   94   | 45  |               35               |      2500      |
|   75   | 41  |               0                |      1900      |
|   92   | 26  |               46               |      1500      |
|   92   | 31  |               38               |      800       |
|   94   | 48  |               30               |      1200      |

: Des données individuelles avec des uniques sur les croisements Âge $\times$ Région
:::


## Un exemple



::: {#tbl-ckm-avtg-incv style="font-size: 70%;" .table .table-striped .table-hover .table-bordered}

|                 Région                  |                      Âge                       | Heures travaillées par semaine | Revenu mensuel |
| :-------------------------------------: | :--------------------------------------------: | :----------------------------: | :------------: |
| [92]{style="background-color:#fbff91;"} | [~~36~~ 31]{style="background-color:#fbff91;"} |               17               |      1000      |
| [75]{style="background-color:#ff796d;"} | [~~41~~ 45]{style="background-color:#ff796d;"} |               35               |      2000      |
| [75]{style="background-color:#ff796d;"} | [~~52~~ 45]{style="background-color:#ff796d;"} |               0                |      1100      |
| [94]{style="background-color:#baf2c2;"} | [~~45~~ 47]{style="background-color:#baf2c2;"} |               35               |      2500      |
| [75]{style="background-color:#ff796d;"} | [~~41~~ 45]{style="background-color:#ff796d;"} |               0                |      1900      |
| [92]{style="background-color:#fbff91;"} | [~~26~~ 31]{style="background-color:#fbff91;"} |               46               |      1500      |
| [92]{style="background-color:#fbff91;"} | [~~31~~ 31]{style="background-color:#fbff91;"} |               38               |      800       |
| [94]{style="background-color:#baf2c2;"} | [~~48~~ 47]{style="background-color:#baf2c2;"} |               30               |      1200      |

: Des données individuelles avec des uniques sur les croisements Âge $\times$ Région
:::
  <!-- -------- ----------- -------------------- ------------
   Région      Age      Heures travaillées     Poids
                           par semaine       de sondage
     92     ~~36~~ 31           17              1000
     [red]{style="color:green;"}75     ~~41~~ 45           35              2000
     75     ~~52~~ 45           0               1100
     94     ~~45~~ 47           35              2500
     75     ~~41~~ 45           0               1900
     92     ~~26~~ 31           46              1500
     92     ~~31~~ 31           38              800
     94     ~~48~~ 47           30              1200
  -------- ----------- -------------------- ------------ -->

-   $\mu_{red} = 45$, $\mu_{yellow} = 31$, $\mu_{green} = 47$


## Paramètres 

Un grand nombre de sorties possibles pour cette méthode selon :

-   la définition d'homogénéité choisie

-   l'algorithme utilisé pour construire les groupes

-   la détermination de la valeur de remplacement

Les paramètres à définir :

-   Taille $g$ de chaque groupe (plus la taille du groupe est grande, plus grande sera la perte d'information, et plus celle-ci est grande, plus le niveau de protection est élevé ..)

-   Quelles variables sont utilisées pour calculer la distance ?

-   Quelles statistiques choisir une fois que les groupes ont été formés ? (moyenne, médiane ?)

## Minimiser la variance intra-groupe 

::: {style="text-align:center;"}
![Table après perturbation](img/within.png){#fig-within width=50% fig-alt="Minimisation de la variance intra-groupe" fig-align="center"}
:::

L'algorithme cherche à minimiser la somme des carrés intra-groupe:

$$SSE = \sum_{i=1}^g\sum_{j \in i} (x_{ij}-\bar x_{i})^T(x_{ij}-\bar x_{i})$$


## Avantages / inconvénients

::: {#tbl-bruit-add-avtg-incv style="font-size: 70%;" .table .table-striped .table-hover}
|                Avantages                |       Inconvénients       |
| :-------------------------------------: | :-----------------------: |
|         Adapté au $k$-anonymat          | Temps de calcul important |
| Des classes statistiquement pertinentes |                           |

: Avantages et inconvénients de l'injection d'un bruit additif
:::


# Injection de bruit

## Injection de bruit

-   Méthode adaptée pour traiter les variables continues

-   En général, on injecte un bruit additif sans biais et à variance fixe

-   Enjeu principal: comment bruiter en préservant les caractéristiuqes des variables et de leurs éventuels liens ?

## Perturbation par un bruit additif

-   Un bruit est ajouté à chaque valeur observée
-   Généralement un bruit gaussien d'espérance nulle
-   Adapté aux variables continues de faible amplitude

## Bruits additifs indépendants

- Chaque variable est bruitée indépendamment des autres variables

- Les moyennes et covariances de chaque variable perturbée sont préservées

- Mais, les variances et les coefficients de corrélation ne sont pas conservés

## Bruits additifs corrélés

-  La matrice de variance-covariance des bruits est proportionnelle à la matrice de variance covariance des valeurs originales

-  Conservation de la moyenne et des coefficients de corrélation

-  Préférable à l'ajout des bruits indépendants car on peut obtenir des estimations non biaisées pour plusieurs statistiques importantes

## Avantages / inconvénients

::: {#tbl-bruit-add-avtg-incv style="font-size: 70%;" .table .table-striped .table-hover}
|                  Avantages                  |                       Inconvénients                        |
| :-----------------------------------------: | :--------------------------------------------------------: |
| Traitement de variables sensibles continues | Pas adapté aux traitements des outliers de grandes valeurs |
|  Préservations de statistiques importantes  |                                                            |

: Avantages et inconvénients de l'injection d'un bruit additif
:::
                           


# Targeted Record Swapping (TRS)

## Targeted Record Swapping (TRS)

::: {.callout-note}
### Définition

Le `Target Record Swapping (TRS)` est une méthode s'appliquant directement sur un jeu 
de données individuelles pour réduire les risques de ré-identification.

Il consiste à échanger la localisation de certains individus jugés à risque avec d'autres individus d'une autre entité géographique.

D'où son nom: le *swapping*, c'est-à-dire 
l'échange, va concerner des unités de la base (les *records*) détectés à l'avance, 
devenant ainsi les cibles (*target*) sur lesquelles l'échange se concentrera.

:::

## Les individus à risque (cibles)

- Cible les individus à risque:
  - Détection par $k$-anonymat:  croisements de quasi-identifiants de moins de $k$ individus
  - Détection par $l$-diversité: homogénéité d'un groupe sur une variable sensible
  - Mesure probabiliste du risque individuel
  - Principalement un risque de ré-identification

## Une méthode très utilisée

-   Insee: Données européennes du recensement 2021

-   Eurostat préconise cette méthode (couplée à la CKM) pour la diffusion du Census européen

-   US Census Bureau: Recensement US 2010

-   ONS (UK): Recensement depuis 2010


## Un exemple

::: {style="text-align:center;"}
![Avant Swapping](img/swapping-exemple-avant.png){#fig-swap-avt width=80% fig-alt="Avant swapping" fig-align="center"}
:::

## Un exemple

::: {style="text-align:center;"}
![Après Swapping](img/swapping-exemple-apres.png){#fig-swap-apr width=80% fig-alt="Après swapping" fig-align="center"}
:::


## Avantages / inconvénients

::: {#tbl-trs-avtg-incv style="font-size: 70%;" .table .table-striped .table-hover}
|                                          Avantages                                          |                                                Inconvénients                                                |
| :-----------------------------------------------------------------------------------------: | :---------------------------------------------------------------------------------------------------------: |
|                      Efficace pour traiter différents types de risque                       | Nécessite de fixer un grand nombre de paramètres (mesure de risque, variables similarité, taux de swapping) |
| Méthode souple, adaptation à des cas très différents (structures ménages-individus par ex.) |                        Bruit injecté dans les données n'est pas vraiment contrôlable                        |
|    Préserve les agrégats du niveau géographique au sein duquel le swapping a été opéré.     |                                 Génère localement du biais dans les données                                 |
|       Conserve l'additivité des tableaux générés à partir des micro-données bruitées.       |                                                                                                             |

: Avantages et inconvénients du TRS
:::
        

# Post-Randomisation Method (PRAM)

## Méthode PRAM
-   Permet de traiter les **variables** sensibles **catégorielles** en bruitant les données. 

-   Consiste à modifier aléatoirement l'appartenance des individus à une classe donnée.

-   Méthode particulièrement intéressante pour traiter les **divulgations d'attributs sensibles** : un attaquant ne peut avoir aucune certitude sur l'attribut d'une observation.


## Un exemple

  -------- ----- ------------------
   Region   Age  Situation pro.
     92     14        Inactif
     75     41        Chômeur
     75     52         Actif
     94     45         Actif
     75     41        Chômeur
     92     26         Actif
     92     31         Actif
     94     14        Inactif
  -------- ----- -------------------

-   Inactif : 2 ind., Chômeur = 2 ind., Actif = 4 ind.

## Un exemple

  -------- ----- ----------------- --------------------------------
   Region   Age   Situation pro.      Situation pro. (PRAM)
     92     14        Inactif       [Chômeur]{style="color: red"}
     75     41        Chômeur        [Actif]{style="color: red"}
     75     52         Actif         [Actif]{style="color: blue"}
     94     45         Actif         [Actif]{style="color: blue"}
     75     41        Chômeur       [Inactif]{style="color: red"}
     92     26         Actif         [Actif]{style="color: blue"}
     92     31         Actif        [Chômeur]{style="color: red"}
     94     48        Inactif       [Inactif]{style="color: blue"}
  -------- ----- ----------------- --------------------------------

-   Inactif : 2 ind., Chômeur = 2 ind., Actif = 4 ind.

## Un exemple

  -------- ----------------------------- ----------------- -----------------------------------
   Region             Age                   Situation pro.      Situation pro. (PRAM) 
     92     [**14**]{style="color: red"}       Inactif       [**Chômeur**]{style="color: red"}
     75                41                      Chômeur                     Actif
     75                52                      Actif                      Actif
     94                45                      Actif                      Actif
     75                41                      Chômeur                    Inactif
     92                26                      Actif                      Actif
     92                31                      Actif                     Chômeur
     94                48                     Inactif                    Inactif
  -------- ----------------------------- ----------------- -----------------------------------

-   Attention aux incohérences !

## La matrice de transition

On a besoin de définir une [**matrice de transition**]{style="color: red"} pour pouvoir définir les probabilités de transition.

-   Soit $\xi$ la variable catégorielle initiale avec $K$ catégories $1 \dots K$\
    $\rightarrow$ dans l'exemple, $\xi$ = Situation professionnelle, K = 3

-   Soit $X$ la même variable catégorielle dans le jeu de données perturbé\
    $\rightarrow$ dans l'exemple, $X$ = Situation professionnelle (PRAM)

## La matrice de transition
On peut définir la matrice de transition $P$, 

$$P =(p_{kl})_{1 \leq k,l \leq K}$$ 

où $p_{kl} = P(X =l|\xi = k)$


![](./img/matrice_transition_PRAM.png){width=5% fig-align="center"}  

## Comment choisir la matrice de transition ?

-   PRAM change aléatoirement les comptages de la population :

    $$\mathbb{E}\begin{pmatrix} N^{pram}_{I} \\N^{pram}_{E}\\ N^{pram}_{U} \end{pmatrix} = P^{T} \begin{pmatrix}N_{I} \\N_{E}\\ N_{U} \end{pmatrix}$$

-   Selon P **[et les comptages originaux]{style="color: red"}**, les marges peuvent être beaucoup perturbées !

-   Des coefficients diagonaux élevés peuvent être insuffisants

## Un exemple numérique

-   Marges originales

                         Inactif   Actif   Chômeur
  --------------------- --------- ------- ---------
  Fréquence (million)     16.8      49       4.2
  Pourcentage             24 %     70 %      6 %

-   Matrice de transition $P$ :

   ![](./img/matrice_transition_PRAM.png){fig-align="center"} 


## Un exemple numérique

On peut maintenant calculer les marges perturbées !

-   Marges originales 

    | Statut               | Inactif | Actif | Chômeur |
    |----------------------|---------|-------|---------|
    | Fréquence (million)  | 17      | 49    | 4       |
    | Pourcentage          | 24%     | 70%   | 6%      |


-   Nouvelles marges

    | Statut               | Inactif | Actif | Chômeur                |
    |----------------------|---------|-------|------------------------|
    | Fréquence            | 14      | 41    | **<span style="color:red">16</span>** |
    | Pourcentage          | 20%     | 58%   | <span style="color:red">22 %</span>   |


## PRAM Invariant

-   Possibilité de choisir la matrice $P$ de telle sorte que la perturbation soit sans biais $\rightarrow$ PRAM invariant

-   Etant donné que : $$\mathbb{E}\begin{pmatrix} N^{pram}_{I} \\N^{pram}_{E}\\ N^{pram}_{U} \end{pmatrix} = P^{T} \begin{pmatrix}N_{I} \\N_{E}\\ N_{U} \end{pmatrix}$$

-   Il faut, pour cela, choisir $P$ telle que les fréquences marginales originales soient un vecteur propre de $P$ associé à la valeur propre $1$.

## Mesurer le niveau de protection

-   PRAM introduit délibérement une erreur de mesure $\rightarrow$ on ne peut pas utilisé le k-anonymat ou la l-diversité

-   Niveau de protection mesuré à partir des paramètres de la méthode (matrice de transition).

-   Idée: faire en sorte que la rareté de certaines modalités soit rendue suffisamment incertaine à inférer $\rightarrow$ posterior odds ratio

## Mesurer le niveau de protection

$$POST\_ODDS(k) = \frac{P(\xi = k|X=k)}{P(\xi \neq k|X=k)} = \frac{p_{kk}P(\xi = k)}{\sum_{l \neq k}p_{lk}P(\xi=l)}$$

-   $p_{kk}$ sont connus et dépendent du plan de sondage
-   $P(\xi = k)$ peut être difficile à estimer
-   on peut estimer grossièrement $P(\xi = k)$ par $\frac{T_\xi(k)}{n}$

## Interprétation

On observe k dans le jeu pertubé :

-   Si $POST\_ODDS(k) > 1$, alors la valeur originale est plus probablement **$k$** plutôt qu'une autre valeur.

-   Si $POST\_ODDS(k) < 1$, alors la valeur originale est plus probablement une **autre valeur** que $k$.

## Avantages / inconvénients



::: {#tbl-pram-avtg-incv style="font-size: 70%;" .table .table-striped .table-hover}
|                                                        Avantages                                                        |                                              Inconvénients                                              |
| :---------------------------------------------------------------------------------------------------------------------: | :-----------------------------------------------------------------------------------------------------: |
| Permet de fournir le niveau de protection associé au bruit injecté en calculant les probabilités de transition inverses |              Création d'éventuelles combinaisons impossibles (ex : enfant à la retraite).               |
|                     Conserve l'additivité des tableaux générés à partir des micro-données bruitées.                     | Difficile de définir une matrice de protection qui prend en compte les liens avec toutes les variables. |                                                                                                        

: Avantages et inconvénients de PRAM
:::


# Les données synthétiques

-   Idée: Générer tout ou partie des données individuelles.

-   Deux types de synthèse:

    -   Synthèse complète: toutes les variables et tous les individus sont générés.

    -   Synthèse partielle: Seulement certaines variables sont générées (principalement les variables sensibles).

## Modélisation séquentielle

::: {.callout-note}
### Fully Conditional Specification

Chaque variable du jeu de données est modélisée séquentiellement et conditionnellement aux variables précédentes.

Pour générer la $p^e$ variable, on cherche à modéliser sa distribution conditionnelle : 

$$f_{X_p | X_1 , X_2 , \dots , X_{p-1}}$$

Modèles statistiques couramment utilisés:
  - modèles paramétriques (régression linéaire ou logistique) 
  - méthodes à base d'arbres: CART, Boosting, random forest, XGBoost.

:::

## Les méthodes Deep Learning (I)

::: {.callout-note}
### Tabular Variational Auto Encoder (TVAE)

L'auto encodage consiste à combiner **une phase d'encodage** qui réduit la dimension des données pour apprendre les caractéristiques les plus importantes et **une phase de décodage** pour reconstituer des données dans leur dimension originale.

:::


## Les méthodes Deep Learning (II)

::: {.callout-note}
### Conditional Tabular Generative Adversarial Network (CTGAN)

Les GAN sont très populaires dans la génération d'images. Les CTGAN sont une adaptation des GAN pour générer des données tabulaires (microdonnées ou données agrégées). Un générateur construit des données synthétiques et les soumet à un discriminateur dont l'objectif est de distinguer ces données générées des données originales.

:::
    
## Références

::: {#refs}
:::