---
title: Appliquer le Target Record Swapping
href: pratique/fiches/proteger-micro-swapping.html
code-block-bg: true
code-block-border-left: "#bf9aff"
code-fold: show
---


# Objectif:

La fiche pratique présente comment appliquer le `Target Record Swapping` à
un jeu de données individuelles afin d'assurer une protection optimale 
des informations confidentielles des individus (ou ménages ou entreprises) qui 
le composent.

La première partie s'attache à présenter les différentes étapes à suivre pour 
que cette application soit pertinente au regard des données utilisées.

La seconde partie montre comment utiliser la fonction `sdcMicro::recordSwap()` 
pour appliquer la méthode à un jeu de données dont on aura repérer les 
individus à risque préalablement.



::: {.callout-tip}
# Pour s'exercer

Pour reproduire les résultats et réaliser les exercices, il est possible de travailler 
directement sur le [`datalab` de l'Insee](datalab.sspcloud.fr). Si vous disposez d'un compte, vous pouvez [Ouvrir un service RStudio](https://datalab.sspcloud.fr/launcher/ide/rstudio?name=rstudio-formation-protection&version=2.3.1&s3=region-ec97c721&init.personalInit=«https%3A%2F%2Fraw.githubusercontent.com%2FInseeFrLab%2Fformation_protection_donnees%2Frefs%2Fheads%2Fmain%2Finit-scripts%2Frstudio.sh») ou [Ouvrir un service vscode R-Python](https://datalab.sspcloud.fr/launcher/ide/vscode-r-python-julia?name=vscode-formation-protection&version=2.3.5&s3=region-ec97c721&init.personalInit=«https%3A%2F%2Fraw.githubusercontent.com%2FInseeFrLab%2Fformation_protection_donnees%2Frefs%2Fheads%2Fmain%2Finit-scripts%2Fvscode-r-python.sh»), à votre convenance. Ces services installeront automatiquement les packages 
nécessaires pour réaliser les exercices de l'ensemble des fiches pratiques.

:::


# Rappels sur la méthode:

Le `Target Record Swapping (TRS)` est une méthode s'appliquant directement sur un jeu 
de données individuelles pour réduire principalement les risques de ré-identification.
Il ciblera donc les individus pour lesquels ce risque est jugé trop élevé, c'est-à-dire  
ceux partageant des caractéristiques trop rares sur un ensemble 
de variables dites quasi-identifiantes. Les variables quasi-identifiantes sont celles 
qui sont susceptibles d'être déjà publiques ou du moins à la disposition d'un attaquant.

D'où son nom: le *swapping*, c'est-à-dire 
l'échange, va concerner des unités de la base (les *records*) détectés à l'avance, 
devenant ainsi les cibles (*target*) sur lesquelles on va se concentrer.

Bien qu'elle soit appliquée sur des microdonnées, la méthode a principalement vocation à 
protéger la diffusion de données tabulées [@hundepool_handbook_2024, [section 5.6](https://sdctools.github.io/HandbookSDC/05-frequency-tables.html#sec-TRS)]. Dans ce type d'utilisation, en tant que méthode pré-tabulée, 
elle permet de produire des tableaux parfaitement additifs.


## En quoi consiste la méthode ?

Après avoir détecté un individu dont le risque de ré-identification est jugé trop 
élevé, un autre individu est tiré aléatoirement parmi les individus au risque de ré-identification 
les plus faibles et certaines des caractéristiques de ces deux individus sont échangées (*swapped*).

Après l'échange, la ré-identification de l'individu est rendue beaucoup plus difficile et 
ne permet plus d'obtenir d'informations pertinentes à son sujet.


::: {.callout-note}
### Un exemple très simple. 

Soit un territoire donné découpé en six zones où résident un certain nombre d'individus. 
Avec les informations disponibles à leur sujet, on considère qu'un seul individu a un risque 
de ré-identification trop élevé (croix rouge sur la @fig-swap-avant).


::: {#fig-swap-avant}

![Avant swapping](images/swapping-exemple-avant.png)

:::


On tire alors au hasard un autre individu présent sur le territoire pour échanger 
certaines de leurs caractéristiques. Ce tirage pourrait être purement aléatoire. Mais, cela 
conduirait à détruire certaines statistiques bien utiles. Par exemple, en trouvant 
un individu d'une autre zone partageant certaines caractéristiques (par exemple 
le sexe, l'âge et la catégorie sociale, @fig-swap-apres), on s'assure de conserver les marges 
sur ces variables au niveau géographique le plus fin. 

En revanche, les autres caractéristiques sont bruitées de façon non contrôlée.

::: {#fig-swap-apres}

![Après swapping](images/swapping-exemple-après.png)
:::

Ainsi, l'éventuelle ré-identification de l'individu à risque ne pourrait conduire 
l'attaquant qu'à obtenir des informations très probablement fausses à son sujet.

:::

## Les variables de similarité

La méthode est très souple puisqu'elle permet de s'adapter aux données dont on dispose et 
aux besoins en termes de diffusion. Les **variables de similarité** entre individus échangés 
peuvent ainsi être choisies parmi les variables dont on veut conserver 
le mieux possible l'information marginale. En effet, en échangeant des individus 
parfaitement similaires sur certaines caractéristiques (**les variables de similarité**), 
l'échange ne produira aucune perte d'information sur celles-ci. 

::: {.callout-warning}
### Similarité et ré-identification

Si l'objectif est de réduire le risque de ré-identification, sélectionner toutes les variables 
quasi-identifiantes comme variables de similarité ne perturberait aucunement 
la capacité de l'attaquant à ré-identifier les individus. Ce choix produirait 
en revanche du bruit sur les autres variables: donc en ré-identifiant, l'attaquant 
ne serait pas en mesure d'obtenir des informations supplémentaires fiables.

:::

::: {.callout-tip}
### Utiliser la hiérarchie des emboîtements géographiques

Les données contiennent généralement des informations géographiques. Or, la géographie, 
en particulier à des niveaux fins, est très identifiante. On choisira en général 
d'échanger des individus résidant à des endroits différents, en tenant compte 
du niveau géographique auquel un individu est facilement ré-identifiable.

Par exemple, si un individu est facilement ré-identifiable dans sa commune mais 
pas dans son département de résidence, alors on privilégiera l'échange avec 
un autre individu du département en dehors de la commune de notre individu à risque.
Si le niveau départemental posait lui aussi problème on remonterait au niveau régional, etc.

Ainsi, en général, la méthode consistera à échanger la localisation d'individus ou de ménages [@longhurst_statistical_nodate].

:::


### Comment définir des individus similaires ?

La **similarité** entre deux individus peut être envisagée de deux manières:

- en cherchant la **correspondance exacte** sur les variables de similarité, quitte à relâcher 
des contraintes quand il n'y pas de donneur: un donneur est tiré aléatoirement parmi la liste 
des prétendants.
- en calculant une **distance** entre le receveur et l'ensemble des donneurs: un donneur est 
tiré parmi les individus avec lesquels la distance est la plus faible.

La première option nécessite d'utiliser uniquement des variables catégorielles, 
quitte à créer des classes pour les variables continues qu'on souhaiterait inclure 
dans la liste. 

Dans la pratique, cette première option est la moins gourmande en ressources de calcul, 
car elle ne nécessite pas de calculer une distance entre chaque receveur et chaque donneur potentiel. 
Elle est probablement la seule envisageable si le jeu de données contient plusieurs millions de lignes.



::: {.callout-tip}
### Une astuce pour gérer la présence de poids de sondage

Si nous disposons d'un échantillon, chaque individu dispose d'un poids de sondage. 
Avec le `Target Record Swapping`, on prend le risque d'échanger deux individus avec des poids très différents et 
de déséquilibrer des agrégats importants. Pour éviter ce genre de désagrément, il est possible
d'ajouter le poids parmi les variables de similarité, sous la forme d'un arrondi à l'unité 
ou bien de tranches de valeurs. On pourra également exclure des donneurs potentiels, 
les individus ayant des poids très élevés comparés aux autres. Ceci permettra de limiter 
les déformations des distributions.

:::


### Individus ou ménages ?

Une autre souplesse de la méthode est de pouvoir prendre en compte des 
structures hiérarchiques entre les individus. Par exemple, lorsque le fichier 
d'individus contient également des informations sur la composition des ménages. 

Dans ce cas, l'échange d'individus risque de déstabiliser la composition des 
ménages concernés, en termes d'âge en particulier: on pourrait voir se créer des 
ménages où il n'y a aucun individu majeur par exemple. 

Une solution consisterait à échanger des ménages entiers plutôt que des individus. 
Mais cette solution n'est à retenir que si on dispose de suffisamment d'informations 
sur les ménages pour détecter des ménages similaires de bonne qualité. 
Si ce n'est pas le cas, il peut être préférable d'échanger des individus et de contrôler 
d'une autre manière, car un choix judicieux de variables de similarité peut limiter ces 
désagréments.

<!-- La @tbl-exemple-ind-men présente un exemple de données individuelles contenant une information 
sur la composition des ménages. Ici, les individus sont répartis en deux ménages de trois individus, dont deux adultes.
Pour chaque individu, une mesure de risque de ré-identification est fournie. Le premier individu 
est le seul dont le risque de ré-identification est très élevé. 


| ID  | Géo. | Sexe | Age | Statut    | Diplome | Catégorie<br>Sociale | Risque | Ménage |
|-----|------|------|-----|-----------|---------|----------------------|-------:|--------|
| ID1 | C1   | H    | 35  | Chômage   | Bac+2   | Employé              |      1 | MEN1   |
| ID2 | C1   | F    | 40  | En emploi | Bac+5   | Cadre                |   0,05 | MEN1   |
| ID3 | C1   | F    | 12  | Inactif   |         | Elève                |   0,05 | MEN1   |
| ID4 | C2   | H    | 55  | En emploi | Bac+5   | Cadre                |   0,05 | MEN2   |
| ID5 | C2   | F    | 53  | En emploi | Bac+5   | Cadre                |   0,05 | MEN2   |
| ID6 | C2   | H    | 17  | Inactif   | BEP     | Ouvrier              |   0,05 | MEN2   |


: Table indiviudelle et composition des ménages {.striped #tbl-exemple-ind-men}


:::: {.columns}

::: {.column width="45%"}

:::

::: {.column width="5%"}

:::

::: {.column width="45%"}

:::

::::
 -->

### Le taux de *swapping*

Le __taux d'échange__ ou __taux de *swapping*__ est la part d'individus du jeu de données 
qui a pris part aux échanges, soit $s=\frac{E+D}{N}$, où $E$ est le nombre d'individus à échanger,
$D$ le nombre de donneurs ($D=E$) et $N$ le nombre d'individus dans la base. 

En pratique, on fixe un taux de swapping $s$ de telle sorte que l'algorithme procède à un minimum 
d'échanges. Si le nombre d'individus à risque ne permet pas d'atteindre ce seuil, des individus 
supplémentaires seront également échangés pour atteindre $s$. Sinon, le taux de swapping étant atteint ou dépassé,
aucun individu additionnel n'est ajouté.


## Les grandes étapes à suivre pour appliquer le `TRS`

1. De quels risques cherche-t-on à se protéger ?
   1. Si c'est du risque de ré-identification, le `TRS` est une méthode adaptée
   2. Sinon, il faut peut-être aller voir ailleurs.
2. Quelles sont les variables quasi-identifiantes dans mes données ?
3. Mesurer le risque de ré-identification basé sur ces variables ? 
4. Choisir un seuil de risque de ré-identification maximal acceptable, au-delà duquel les individus devront être traités.
5. Quelles sont les marges que la méthode devrait conserver intactes en priorité ?
6. Un *swapping* des ménages est-il préférable à un swapping d'individus ? 
7. Sélection des paramètres de la méthode:
   1. Les variables de similarités, en tenant compte des risques et des objectifs de diffusion.
   2. Le taux de swapping.
8. Procéder au swapping
9. Mesurer la perte d'information 
10. Reprendre les étapes 4. à 9. si la perte d'information s'avère trop grande ou la protection trop faible


L'avantage de la méthode  est sa grande capacité d'adaptation aux données dont on dispose. 
Même si cette fiche va présenter comment l'appliquer avec le package `sdcMicro`, 
il est en réalité tout à fait possible de développer son propre algorithme pour 
affiner la façon de tirer les individus ou les ménages à échanger.


On pourra se reporter à la 
[fiche sur les mesures de risque](pratique/fiches/mesurer-risque.html) 
pour en savoir plus sur les risques et la façon de les mesurer.



# En pratique

Pour installer les packages nécessaires, vous trouverez les instructions à suivre 
dans la fiche [Ressources / Installer les packages et les outils sur R](../../ressources/fiches/outils-install.html).  


## Les packages

```{r}
#| eval: false
#| echo: false
setwd("./pratique/fiches")
```


```{r}
#| echo: false
library(readr)
library(purrr)
library(dplyr)
library(sdcMicro)
```

## Les données

```{r}
source("../R/fun_import_data.R")
lfs_2023 <- import_lfs()
```


```{r}
head(lfs_2023)
```

Pour plus d'informations sur les données, on pourra se reporter à la fiche 
["Présentation des données"](description-data.html).  


## Mesurons les risques du fichier

### Les types de variables

On définit les variables selon les différentes catégories suivantes:

- les variables quasi-identifiantes (`key_vars`)
- les variables sensibles (`sens_vars`)
- les variables identifiant la composition des ménages (`hhid_vars`)

Pour cet exercice, nous ferons les choix suivants:

```{r}
key_vars <- c("AGE","SEXE","DEP","DIP7")
sens_vars <- c("ACTEU","ANCCHOM","IS_CHOM")
hhid_vars <- c("HHID")
```

Les comptages par croisement des modalités des variables quasi-identifiantes:

```{r}

```

La part des individus ne respectant pas appartenant à des groupes de moins de $k$ individus est fournie par la table ci-dessous:

```{r}
mesurer_risk_reidentif <- function(data, key_vars, ks){
  groupes_QI <- data |> 
    count(across(all_of(key_vars))) |>
    arrange(n)
  risk_quantif <- map(
  ks,
  \(k){
    groupes_QI |>
      summarise(part = sum(n[n<k])/sum(n)*100, .groups="drop")|>
      mutate(k=k)
  }
  ) |>
    purrr::list_rbind()
}
```

```{r}
risk_mes <- mesurer_risk_reidentif(lfs_2023, key_vars, ks= 2:10)
```

```{r}
#| echo: false
#| fig-cap: "Part d'individus à risque de ré-identification en fonction du niveau d'anonymité choisi"
risk_mes |>
  select(k, part) |>
  knitr::kable(digits=1)
```

Comme l'âge détaillé est une variable utilisée dans les quasi-identifiants, la part d'individus à risque de réidentification est assez importante (plus de la moitié des individus dès lors que $k\geq4$).

Si on choisit de ne diffuser que la variable de tranche d'âge, on réduit sensiblement ce risque:

```{r}
key_vars2 <- c("AGE6","SEXE","DEP","DIP7")
risk_mes2 <- mesurer_risk_reidentif(lfs_2023, key_vars2, ks= 2:10)
```

```{r}
#| echo: false
#| fig-cap: "Part d'individus à risque de ré-identification en fonction du niveau d'anonymité choisi"
risk_mes2 |>
  select(k, part) |>
  knitr::kable(digits=1)
```

Dès lors, avec $k=10$, on dénombre `7.3%` d'individus à risque de ré-identification.


On peut retrouver ces mêmes résultats avec le package `sdcMicro`:

```{r}
lfs_sdc <- sdcMicro::createSdcObj(
  lfs_2023,
  keyVars = key_vars2
)
```

```{r}
print(lfs_sdc, 'kAnon')
```

La part d'individus à risque de ré-identification pour $k=10$:
```{r}
mean(lfs_sdc@risk$individual[,2] < 10)*100
```

## Préparation pour le swapping

```{r}
risk_variables <- c("AGE6","SEXE","DIP7")
hierarchy <- c("REG", "DEP")
carry_along <- NULL
hid <- "ID" # swapping d'individus
```

```{r}
lfs_2023_pr_swap <- lfs_2023 |>
  select(all_of(c(risk_variables, hierarchy, similar, sens_vars, hhid_vars))) |>
  mutate(across(everything(), as.integer))|>
  mutate(ID = 1:n())
```


### Swapper les individus

Les paramètres:

```{r}
k_anonymity <- 5
swaprate <- .1
```

```{r}
lfs_swapped <- recordSwap(
  data = lfs_2023_pr_swap,
  hid = hid,
  hierarchy = hierarchy,
  similar = similar,
  risk_variables = risk_variables,
  carry_along = carry_along,
  k_anonymity = k_anonymity,
  swaprate = swaprate,
  return_swapped_id = TRUE,
  seed = 123456
)
```

Le taux de swapping réel:

```{r}
lfs_swapped %>% summarise(mean(ID != ID_swapped))
```

```{r}
lfs_swapped %>% group_by(REG) %>%
  summarise(mean(ID != ID_swapped))
```


#### Vérifier que les individus à risque ont bien été swappés

```{r}
lfs_swapped 
```

#### Intégrité de la composition des ménages



### Swapper les ménages


```{r}
hid <- "HHID" # swapping de ménages
similar <- "TAILLE"

lfs_swapped_hh <- recordSwap(
  data = lfs_2023_pr_swap,
  hid = hid,
  hierarchy = hierarchy,
  similar = similar,
  risk_variables = risk_variables,
  carry_along = carry_along,
  k_anonymity = k_anonymity,
  swaprate = swaprate,
  return_swapped_id = TRUE,
  seed = 123456
)
```


#### Taux de swapping des ménages vs taux de swapping des individus

```{r}
lfs_swapped_hh %>% summarise(mean(HHID != HHID_swapped)) #6.2 des ménages
lfs_swapped_hh %>% filter(HHID != HHID_swapped) %>%
  summarise(n()/nrow(lfs_swapped_hh)*100) #6.2% des individus (les ménages swappés sont de même taille)
lfs_swapped_hh %>% filter(HHID != HHID_swapped) %>%
  summarise(mean(TAILLE))

```

## Mesurer la perte d'utilité 


Comparer différents taux de swapping.

### Comparer les intervalles de confiance d'un modèle logistique

```{r}
source("../R/fun_cio.R")
```


Étudions la stabilité d'un modèle relativement simple, cherchant à expliquer 
le fait d'être au chômage par différentes variables à notre disposition:
l'âge, le diplôme et le sexe.

On entraînera ce modèle uniquement sur la population active. On retire donc notamment 
la population étudiante et retraitée.


```{r}
m_original <- glm(IS_CHOM ~ SEXE + AGE6 + DIP7, data = lfs_2023 |> filter(ACTEU != 3))
m_swapped <- glm(IS_CHOM ~ SEXE + AGE6 + DIP7, data = lfs_2023 |> filter(ACTEU != 3))

mes_modeles <- list(
  "original" = m_original,
  "swapped" = m_swapped
)

all_cios <- get_all_confints(mes_modeles)
```


```{r}
graph_cios(all_cios, titre = "Superposition des intervalles de confiance\ndes Odds Ratio du modèle selon le jeu de données") +
  theme(axis.text.y =  element_text(size = 8))
```


## Exercices

### Choisir le taux de swapping 

### Appliquer le swapping au niveau ménages